\section{Введение}

Огромная часть машинного обучения основана на решении задачи оптимизации без ограничений

\begin{equation}
    \label{eq:general}
	\min_{w \in \mathbb{R}^d} f(w).
\end{equation}


Задачи вида \eqref{eq:general} охватывают множество приложений, включая минимизацию эмпирического риска \citep{chapelle2000vicinal},
глубокое обучение \citep{lecun2015deep}, и задачи обучения с учителем \citep{cunningham2008supervised} такие, как наименьшие квадраты с регуляризацией \citep{rifkin2007notes} или логистическая регрессия \citep{shalev2014understanding}.

Классический метод решения задачи оптимизации \eqref{eq:general} это градиентный спуск.

\begin{equation}
    \label{GD}
	w_{t+1} = w_t - \eta \nabla f(w_t),
\end{equation}

Задача минимизации \eqref{eq:general} может быть трудноразрешимой особенно, когда размер выборки крайне велик или размерность задачи велика.

В таких случаях подсчет полного градиента на каждой итерации в градиентном спуске становится очень дорогим в плане времени или вычислительных ресурсов, которые нужны для этого, особенно учитывая, что градиентному спуску часто требуется большое количество итераций для сходимости.
В современном машинном обучении, особенно с появлением глубокого обучения, растет интерес к решению все более больших и сложных задач. Популярным решением для таких проблем стал стохастический градиентный спуск \citep{robbins1951stochastic}.


С течением времени методы оптимизации постоянно совершенствовались и развивались, становясь все более сложными и запутанными.
Одним из важнейших аспектов в оптимизации является правильный подбор размера шага в ходе итерационного процесса.
Адаптивные методы с градиентным масштабированием динамически регулируют 
этот размер шага на основе информации о градиенте. Такое адаптивное поведение, применяемое к каждой переменной, улучшает процесс оптимизации, эффективно перемещаясь по сложным ландшафтам и обеспечивая оптимальный прогресс для каждой переменной \citep{hazan2007adaptive}. В частности, эти методы приобрели значительную популярность в области машинного обучения, где преобладают высокоразмерные задачи \citep{zhang2018three, yao2021adahessian}.

Более подробно под методами с масштабированным градиентом понимаются техники, предполагающие предобуславливание градиента задачи по определенной матрице $D_t$, что позволяет градиенту учитывать геометрию задачи. В общем случае шаг алгоритмов с предуславливанием может быть выражен как следующая модернизация шага \eqref{GD}:
\begin{equation}
    w_{t+1} = w_t - \eta \cdot D_t^{-1} g_t,
\end{equation}
где $g_t$ - несмещенный стохастический градиент.

Идея использования матрицы шкалирования отсылает нас к методу Ньютона, где $D_t = \nabla^2 f(w)$. Однако вычисление и обращение гессиана сопряжено со значительными трудностями, что приводит нас к необходимости использования определенных эвристик в качестве замены матрицы $D_t$. Примерами таких эвристических методов являются Adagrad \citep{duchi2011adaptive}, Adam \citep{kingma2014adam}, RMSProp, OASIS \citep{goldberg2011oasis} и так далее, где стратегии вычислений для $D_t$ не требуют оценки гессиана.
Например, в Adagrad предусловие представлено в виде:
$$ D_t = \text{diag} \left\{ \sqrt{\sum_{t'=0}^t{g_{t'} \odot g_{t'}}} \right\}, $$
где $\odot$ - Адамарово произведение.  На самом деле этот подход использует только стохастические градиенты.

RMSProp и Adam используют похожие идеи:
$$ D_t^2 = \beta D_{t-1}^2 + (1 - \beta) \text{diag} \left\{ g_{t} \odot g_{t} \right\} $$
где $\beta \in (0, 1)$ представляет собой степень учета предыдущих итераций \citep{kingma2014adam}.

В OASIS используется другой подход:
$$ D_t = \text{diag} \left\{ z_k \odot \nabla^2 f(w_t) z_k \right\}, $$
где $z_k$ - случайный вектор из распределения Рандамахера, т.е. каждый элемент вектора $z_k^i \in \{-1, 1\}$ с вероятностью $\frac{1}{2}$ \citep{goldberg2011oasis}. На первый взгляд кажется, что используется матрица гессиана, но на самом деле она аппроксимируется через дифференцирование скалярной функции.

Несмотря на преимущества методов предобусловливания, они склонны к переобучению, таким образом, возникает необходимость в их совместном применении с регуляризацией. Этот подход широко применяется для решения различных задач машинного обучения, включая классификацию изображений \citep{zhu2017learning}, распознавание речи \citep{zhou2017improved} и обработку естественного языка \citep{wu2022stgn}, и показал свою эффективность в улучшении обобщающей способности нейронных сетей \citep{girosi1995regularization}. 

С регуляризацией задача \eqref{eq:general} переформулируется как
\begin{equation} \label{F_big}
	\min_{w \in \mathbb{R}^d} F(w) := f(w) + r(w),
\end{equation}
где $r$ - функция регуляризации.

В методах с предуславливанием есть несколько способов добавления регуляризации.
Можно добавить регуляризатор $r$ в подсчет $g_t$, и тогда он будет учитываться при вычислении $D_t$. Этот способ равносилен рассмотрению оптимизационной задачи \eqref{F_big}.
Или же мы можем добавить регуляризатор только на последнем шаге, уменьшая норму $w$ \citep{loshchilov2017decoupled}.
Такой способ регуляризации называется затуханием весов и, как ни странно, оказывается более эффективным в практических задачах.
Существует и другой способ рассмотрения регуляризатора, который будет рассмотрен далее в статье.

Несмотря на свою практическую эффективность, методы, использующие затухание весов, относительно мало изучены с точки зрения теории сходимости методов.
В связи с этим возникает ряд исследовательских вопросов:
\begin{itemize}
    \item \textit{Сходятся ли с теоретической точки зрения методы с предобуславливанием и затуханием весов?}
    \item \textit{Если сходятся, то какова скорость их сходимости?}
    \item \textit{К какой задаче они сходятся?}
\end{itemize}
